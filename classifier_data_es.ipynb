{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier_data_es.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/multilingial/blob/master/classifier_data_es.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtjP1obcBbL8",
        "outputId": "755dec52-3b47-419f-d908-490cbec7059c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ObeBkJD06Zu",
        "outputId": "b77d924b-8f6e-44d5-8378-e24a962a4602"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 32.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=08de53986184132f3d759eb10bcf56aae0ed12fc7ac0c932b7d81f938d266668\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN82VCCY1QNA",
        "outputId": "49055c2b-dc25-418b-fc3e-b9cd766a65fa"
      },
      "source": [
        "pip install git+https://github.com/n-waves/multifit"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/n-waves/multifit\n",
            "  Cloning https://github.com/n-waves/multifit to /tmp/pip-req-build-3qymu9m3\n",
            "  Running command git clone -q https://github.com/n-waves/multifit /tmp/pip-req-build-3qymu9m3\n",
            "Building wheels for collected packages: multifit\n",
            "  Building wheel for multifit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multifit: filename=multifit-1.0-cp36-none-any.whl size=24505 sha256=d9edec97729ec31e7b389c3912f06c605f2e422bfddbb4e86e19203b224e9f95\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wx17f6qe/wheels/b7/92/1e/246f31a4e84fd665b5907cb96765f696be45e814ff68a5fd4a\n",
            "Successfully built multifit\n",
            "Installing collected packages: multifit\n",
            "Successfully installed multifit-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVFPZy011RYp",
        "outputId": "cea89c37-efd1-4cf9-d30a-eb5eecc6d23f"
      },
      "source": [
        "pip install sacremoses"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.43)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82jsWtZA1SP6",
        "outputId": "537fac1a-46d7-4841-f9a5-562a54b9c90c"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uNMMBPLBlza",
        "outputId": "fbff2a73-f34e-48ae-9f81-f59873b4fe9a"
      },
      "source": [
        "import glob\r\n",
        "glob.glob('/content/gdrive/My Drive/multilingual/*')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/multilingual/jigsaw-toxic-comment-train.csv',\n",
              " '/content/gdrive/My Drive/multilingual/jigsaw-toxic-comment-train-processed-seqlen128.csv',\n",
              " '/content/gdrive/My Drive/multilingual/validation.csv',\n",
              " '/content/gdrive/My Drive/multilingual/test.csv',\n",
              " '/content/gdrive/My Drive/multilingual/submission.csv',\n",
              " '/content/gdrive/My Drive/multilingual/es']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wm5e1lpBjTX"
      },
      "source": [
        "import pandas as pd\r\n",
        "def load_data():\r\n",
        "    trn=pd.read_csv('/content/gdrive/My Drive/multilingual/jigsaw-toxic-comment-train.csv',usecols=['toxic','comment_text'])\r\n",
        "    tst=pd.read_csv('/content/gdrive/My Drive/multilingual/test.csv',usecols=['lang','content'])  \r\n",
        "    sub=pd.read_csv('/content/gdrive/My Drive/multilingual/submission.csv')  \r\n",
        "    return trn,tst,sub\r\n",
        "train,test,sub=load_data()\r\n",
        "test['toxic']=sub['toxic'].round()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtpMbQGeCBT-"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Dense, Input\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "import transformers\r\n",
        "from transformers import TFAutoModel, AutoTokenizer\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\r\n",
        "from tensorflow.keras.layers import *\r\n",
        "from fastai.text import *\r\n",
        "import multifit"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jcmqB8KgCHK3",
        "outputId": "e4d6ee56-bff3-4244-cbfd-b3f0ea21d37f"
      },
      "source": [
        "es=test.loc[test['lang']=='es'].reset_index(drop=True)\r\n",
        "es.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>lang</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>el skate es unos de los deportes favoritos de ...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Me doy la bienvenida. A este usuari le gusta c...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ES NOTABLEMENTE TENDENCIOSO, NO SE HABLA DE CU...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>El Jardín de infantes Nº938, fundado en 1989, ...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Daré explicaciones y/o aclaraciones a cualquie...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content lang  toxic\n",
              "0  el skate es unos de los deportes favoritos de ...   es    0.0\n",
              "1  Me doy la bienvenida. A este usuari le gusta c...   es    0.0\n",
              "2  ES NOTABLEMENTE TENDENCIOSO, NO SE HABLA DE CU...   es    0.0\n",
              "3  El Jardín de infantes Nº938, fundado en 1989, ...   es    0.0\n",
              "4  Daré explicaciones y/o aclaraciones a cualquie...   es    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itanvsgaE4L-"
      },
      "source": [
        "def set_seed(seed):\r\n",
        "    if seed is not None:\r\n",
        "        torch.manual_seed(seed)\r\n",
        "        torch.backends.cudnn.deterministic = True\r\n",
        "        torch.backends.cudnn.benchmark = False\r\n",
        "        np.random.seed(seed)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "s8DbvZBPCZ_F",
        "outputId": "d3cdff7f-aa70-447c-c9f5-d20a7508c7d6"
      },
      "source": [
        "exp = multifit.from_pretrained(\"es_multifit_paper_version\")\r\n",
        "tokenizer = exp.pretrain_lm.tokenizer\r\n",
        "fa_config =  tokenizer.get_fastai_config(add_open_file_processor=True)\r\n",
        "data_lm = (TextList.from_df(es, **fa_config)\r\n",
        "            .split_by_rand_pct(0.1)\r\n",
        "            .label_for_lm()           \r\n",
        "            .databunch(bs=32))\r\n",
        "exp.finetune_lm.arch.lang = 'es'\r\n",
        "set_seed(42)\r\n",
        "learn = exp.finetune_lm.get_learner(data_lm)  \r\n",
        "    # learn is a preconfigured fastai learner with a pretrained model loaded\r\n",
        "data_lm.show_batch()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/n-waves/multifit-models/releases/download/es_multifit_paper_version/es_multifit_paper_version.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training args:  {'drop_mult': 0.3, 'true_wd': False, 'wd': 1e-07, 'pretrained': False, 'clip': 0.12} config:  {'emb_sz': 400, 'n_hid': 1550, 'n_layers': 4, 'pad_token': 1, 'qrnn': True, 'bidir': False, 'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15, 'tie_weights': True, 'out_bias': True}\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Setting LM training seed seed to 0\n",
            "Loading pretrained weights:  [PosixPath('/root/.fastai/models/es_multifit_paper_version/lm_best'), PosixPath('/root/.fastai/models/es_multifit_paper_version/itos')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  idx_min = (t != self.pad_idx).nonzero().min()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>▁, ▁ xxup ▁no ▁ xxup ▁se ▁ xxup ▁habla ▁ xxup ▁de ▁ xxup ▁cuando ▁ xxup ▁la ▁ xxup ▁tu pac ▁ xxup ▁amenaza ba ▁y ▁ xxup ▁fue ▁ xxup ▁denuncia do ▁ xxup ▁por ▁3 ▁ xxup ▁fiscal es ▁ xxup ▁en ▁ xxup ▁febrero ▁, ▁ xxup ▁ni ▁ xxup ▁de ▁ xxup ▁cama ras ▁ xxup ▁oculta s ▁, ▁ xxup ▁ni ▁ xxup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>▁para ▁que ▁lo ▁cu bri eran ▁en ▁sus ▁fe cho ría s ▁y ▁ahora ▁dice ▁su ▁escrito ▁que ▁es ▁un ▁héroe ▁nacional ▁. ▁ xxmaj ▁band ido ▁de ▁7 ▁su ela s ▁ xxbos ▁ xxfld ▁1 ▁ xxmaj ▁ cre o ▁que ▁después ▁de ▁mi ▁posterior ▁ edi t ▁todo ▁quedó ▁bien ▁. ▁ xxmaj ▁gracias ▁y ▁salud os ▁. ▁ xxbos ▁ xxfld ▁1 ▁ xxmaj ▁se ▁ha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>os ▁. ▁ xxmaj ▁pues ▁bueno ▁, ▁inicia ndo ▁con ▁el ▁tema ▁, ▁muy ▁di fici l mente ▁ cre o ▁que ▁no ▁se ▁haya ▁dado ▁cuenta ▁del ▁tiempo ▁de ▁su ▁bloqueo ▁puesto ▁que ▁siempre ▁, ▁cuando ▁inicia s ▁sesión ▁e ▁intenta s ▁ edi tar ▁, ▁el ▁sistema ▁ te ▁ avi sa ▁de ▁cu án to ▁tiempo ▁es ▁el ▁bloqueo ▁y ▁por ▁qué ▁razones ▁. ▁ xxmaj ▁en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>xxmaj ▁es ▁una ▁traducción ▁de ▁http ▁: ▁/ ▁/ ▁www . ri bb on s o ft . com ▁/ ▁ q ca d . html . ▁ xxmaj ▁no ▁esto y ▁seguro ▁que ▁está ▁bajo ▁ xxup ▁ g f d l ▁/ ▁ xxup ▁ g pl ▁. ▁ xxmaj ▁porque ▁la ▁empresa ▁hace ▁también ▁software ▁que ▁se ▁bloque en ▁después ▁de ▁10 ▁minutos ▁para ▁que ▁la ▁gente</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>▁ xxmaj ▁quizá ▁habría ▁que ▁trasladar lo ▁de ▁momento ▁a ▁ xxmaj ▁intento ▁de ▁ xxmaj ▁golpe ▁de ▁ xxmaj ▁estado ▁en ▁ xxmaj ▁turquía ▁de ▁2016 ▁, ▁pero ▁habría ▁que ▁borra r ▁la ▁re di rec ción ▁que ▁he ▁creado ▁. ▁18 p x ▁ xxmaj ▁me ▁parece ▁bien ▁/ ▁ xxmaj ▁salud os ▁18 p x ▁ xxbos ▁ xxfld ▁1 ▁ xxmaj ▁hijo ▁de ▁pu ta ▁,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDNDj3MNB9mA"
      },
      "source": [
        "# learn.freeze_to(-1)\r\n",
        "# learn.fit_one_cycle(1, 1e-4 * 10, moms=(0.8, 0.7))\r\n",
        "# learn.unfreeze()\r\n",
        "# learn.fit_one_cycle(10, 1e-4, moms=(0.8, 0.7))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRydnRKIMWKC"
      },
      "source": [
        "path='/content/gdrive/My Drive/multilingual toxic/es/es1'\r\n",
        "self=exp.finetune_lm\r\n",
        "CLS_BEST = path+'/cls_best1'\r\n",
        "LM_BEST = path+\"/lm_best1\"\r\n",
        "ENC_BEST = path+\"/enc_best1\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj4uCxyr3kXn",
        "outputId": "be11c7e9-9865-4466-c23d-4f5ea7486ac1"
      },
      "source": [
        "path='/content/gdrive/My Drive/multilingual toxic/es/es1'\r\n",
        "self=exp.finetune_lm\r\n",
        "CLS_BEST = path+'/cls_best'\r\n",
        "LM_BEST = path+\"/lm_best\"\r\n",
        "ENC_BEST = path+\"/enc_best\"\r\n",
        "\r\n",
        "\r\n",
        "experiment_path=Path(path)\r\n",
        "self.experiment_path=experiment_path\r\n",
        "print(\"Experiment\", experiment_path)\r\n",
        "\r\n",
        "#save tokenizer\r\n",
        "tokenizer.save(self.experiment_path, learn=learn)\r\n",
        "learn.to_fp32()\r\n",
        "#save encoder weights to (ENC_BEST,learn.path,learn.model_dir)\r\n",
        "learn.save_encoder(ENC_BEST)\r\n",
        "#save model structure to (LM_BEST, learn.path,learn.model_dir,'.pth')\r\n",
        "learn.save(LM_BEST, with_opt=False)\r\n",
        "# learn.destroy()\r\n",
        "# saving 'seed', 'name', 'arch', 'experiment_path', 'dataset_path', 'num_epochs', 'bs', 'bptt', 'drop_mult', 'dropout_values', 'label_smoothing_eps', 'label_smoothing_eps_norm_by_classes', 'use_adam_08', 'true_wd', 'wd', 'clip', 'fp16', 'lr', 'base' \r\n",
        "# to /content/gdrive/My Drive/multilingual toxic/es/es1/finetuning.json\r\n",
        "# save_paramters(self)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment /content/gdrive/My Drive/multilingual toxic/es/es1\n",
            "Copy sp model from /root/.fastai/models/es_multifit_paper_version to /content/gdrive/My Drive/multilingual toxic/es/es1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "0uTQR6_sRFsP",
        "outputId": "e0d2ef85-ffb3-4905-f3df-096b1080db6b"
      },
      "source": [
        "self=exp.classifier\r\n",
        "es['toxic']=es['toxic'].astype(np.long)\r\n",
        "from pathlib import Path\r\n",
        "data_clas = (TextList.from_df(es,cols=['content','toxic'], **fa_config)\r\n",
        "            .split_by_rand_pct(0.1)\r\n",
        "            .label_from_df('toxic')           \r\n",
        "            .databunch(bs=32))\r\n",
        "l1rn = exp.classifier.get_learner(data_clas)  \r\n",
        "# learn is a preconfigured fastai learner with a pretrained model loaded\r\n",
        "data_clas.show_batch()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using Label smoothing with eps =  0.05\n",
            "Setting Classifier weights seed seed to 0\n",
            "Training args:  {'drop_mult': 0.5, 'wd': 0.01, 'pretrained': False, 'bptt': 70, 'loss_func': FlattenedLoss of LabelSmoothingCrossEntropy(), 'clip': 0.12, 'silent': False} config:  {'emb_sz': 400, 'n_hid': 1550, 'n_layers': 4, 'pad_token': 1, 'qrnn': True, 'bidir': False, 'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15}\n",
            "Loading pretrained model /content/gdrive/My Drive/multilingual toxic/es/es1/enc_best\n",
            "Setting Classifier training seed seed to 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>▁ xxbos ▁ xxfld ▁1 ▁http ▁: ▁/ ▁/ ▁www . the - af c . com ▁/ ▁en ▁/ ▁e vent - in form a tion ▁/ ▁ af c - asi an - cu p - ma tch - off icia l s ▁http ▁: ▁/ ▁/ ▁www . the - af c . com ▁/ ▁en ▁/ ▁compone nt ▁/ ▁ jo om lea gue ▁/ ▁</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁ xxbos ▁ xxfld ▁1 ▁ xxup ▁san ▁ xxup ▁ ba udi lio ▁ n ▁ xxrep ▁ 44 ▁o ▁ xxup ▁san ▁ xxup ▁ ba udi lio ▁ n ▁ xxrep ▁ 44 ▁o ▁ xxup ▁san ▁ xxup ▁ ba udi lio ▁ n ▁ xxrep ▁ 44 ▁o ▁ xxup ▁san ▁ xxup ▁ ba udi lio ▁ n ▁ xxrep ▁ 44 ▁o ▁</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁ xxbos ▁ xxfld ▁1 ▁ xxup ▁señor ▁ xxup ▁ iva n ▁ xxup ▁ ce pe da ▁, ▁ xxup ▁duro ▁ xxup ▁ cri tico ▁ xxup ▁del ▁ xxup ▁mejor ▁ xxup ▁presidente ▁ xxup ▁que ▁ xxup ▁he mos ▁ xxup ▁tenido s ▁ xxup ▁los ▁ xxup ▁colombiano s ▁ xxup ▁ vic tima ▁ xxup ▁de ▁ xxup ▁las ▁ xxup ▁a tro</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁ xxbos ▁ xxfld ▁1 ▁no ▁mas ▁de s on rra s ▁chica s ▁... ▁re be nte mos ▁una ▁re pres a ▁, ▁como ▁, ▁ ra pel ▁, ▁mau le ▁. . ▁ oh ▁haciendo la ▁ xxup ▁esta lla r ▁... ▁ xxup ▁ca os ▁ xxup ▁total ▁ xxup ▁en ▁ xxup ▁chile ▁... ▁ xxup ▁honra ▁ xxup ▁ ah ▁ xxup ▁nivel ▁ xxup</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁ xxbos ▁ xxfld ▁1 ▁ xxup ▁cada ▁ xxup ▁ dia ▁ xxup ▁es ▁ xxup ▁mas ▁ xxup ▁evidente ▁ xxup ▁que ▁ xxup ▁el ▁ xxup ▁pueblo ▁ xxup ▁colombiano ▁ xxup ▁rechaza ▁ xxup ▁cada ▁ xxup ▁vez ▁ xxup ▁mas ▁ xxup ▁los ▁ xxup ▁actos ▁, ▁ xxup ▁poli tica s ▁e ▁ xxup ▁ ide ologi a ▁ xxup ▁po dri da ▁</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAHNpCK0Wj6N"
      },
      "source": [
        "l1rn.unfreeze()\r\n",
        "def _fit_schedule_1cycle(num_epochs, learn):\r\n",
        "        learn.unfreeze()\r\n",
        "        learn.fit_one_cycle(num_epochs, slice(1e-2 / (2.6 ** 4), 2e-2), moms=(0.8, 0.7))\r\n",
        "\r\n",
        "def _fit_schedule_layered(num_epochs, learn):\r\n",
        "        learn.freeze_to(-1)\r\n",
        "        learn.fit_one_cycle(1, 2e-2, moms=(0.8, 0.7))\r\n",
        "        if num_epochs > 1:\r\n",
        "            learn.freeze_to(-2)\r\n",
        "            learn.fit_one_cycle(1, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7))\r\n",
        "            learn.freeze_to(-3)\r\n",
        "            learn.fit_one_cycle(1, slice(5e-3 / (2.6 ** 4), 5e-3), moms=(0.8, 0.7))\r\n",
        "            learn.unfreeze()\r\n",
        "        if num_epochs > 5:\r\n",
        "            learn.fit_one_cycle(num_epochs - 4, slice(1e-3 / (2.6 ** 4), 1e-3), moms=(0.8, 0.7))\r\n",
        "\r\n",
        "def _fit_schedule_2cycle(num_epochs, learn):\r\n",
        "        learn.freeze_to(-1)\r\n",
        "        learn.fit_one_cycle(1, 2e-2, moms=(0.8, 0.7))\r\n",
        "        learn.unfreeze()\r\n",
        "        if num_epochs > 1:\r\n",
        "            learn.fit_one_cycle(num_epochs - 1, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7))\r\n",
        "\r\n",
        "def _fit_schedule_reverse_2cycle(num_epochs, learn):\r\n",
        "        learn.unfreeze()\r\n",
        "        for g in learn.layer_groups[-1:]:\r\n",
        "            for l in g:\r\n",
        "                if not learn.train_bn or not isinstance(l, bn_types): requires_grad(l, False)\r\n",
        "        learn.create_opt(defaults.lr)\r\n",
        "        learn.fit_one_cycle(num_epochs, slice(1e-2 / (2.6 ** 4), 2e-2), moms=(0.8, 0.7))\r\n",
        "        learn.unfreeze()\r\n",
        "        learn.fit_one_cycle(num_epochs, slice(1e-3 / (2.6 ** 4), 2e-3), moms=(0.8, 0.7))\r\n",
        "\r\n",
        "def _fit_schedule_false_wd(self, learn):\r\n",
        "        learn.true_wd = False\r\n",
        "        learn.fit_one_cycle(1, 5e-2, moms=(0.8, 0.7), wd=1e-7)\r\n",
        "        if num_epochs > 1:\r\n",
        "            learn.freeze_to(-2)\r\n",
        "            learn.fit_one_cycle(1, slice(5e-2 / (2.6 ** 4), 5e-2), moms=(0.8, 0.7), wd=1e-7)\r\n",
        "            learn.freeze_to(-3)\r\n",
        "            learn.fit_one_cycle(1, slice(5e-4 / (2.6 ** 4), 5e-4), moms=(0.8, 0.7), wd=1e-7)\r\n",
        "            learn.unfreeze()\r\n",
        "            if num_epochs > 5:\r\n",
        "                learn.fit_one_cycle(num_epochs - 4, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7), wd=1e-7)\r\n",
        "\r\n",
        "# _fit_schedule_1cycle(10,l1rn)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "VVVyTyAoWn3W",
        "outputId": "f129360b-3640-43cb-8e2e-c41abb35e4ce"
      },
      "source": [
        "self.experiment_path = l1rn.path / l1rn.model_dir\r\n",
        "tokenizer.save(self.experiment_path, learn=l1rn)\r\n",
        "l1rn.to_fp32()\r\n",
        "l1rn.save(CLS_BEST, with_opt=False)\r\n",
        "print(\"Classifier model saved to\", self.experiment_path)\r\n",
        "self.save_paramters()\r\n",
        "        # learn.destroy()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copy sp model from /root/.fastai/models/es_multifit_paper_version to multifit_paper_version\n",
            "Classifier model saved to multifit_paper_version\n",
            "Saving dump to multifit_paper_version/classifier.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\\n  \"seed\": 0,\\n  \"name\": \"multifit_paper_version\",\\n  \"arch\": {\\n    \"tokenizer_type\": \"sp\",\\n    \"max_vocab\": 15000,\\n    \"lang\": \"es\",\\n    \"emb_sz\": 400,\\n    \"n_hid\": 1550,\\n    \"n_layers\": 4,\\n    \"qrnn\": true\\n  },\\n  \"experiment_path\": \"multifit_paper_version\",\\n  \"dataset_path\": null,\\n  \"bs\": 18,\\n  \"num_epochs\": 8,\\n  \"drop_mult\": 0.5,\\n  \"dropout_values\": {\\n    \"output_p\": 0.25,\\n    \"hidden_p\": 0.1,\\n    \"input_p\": 0.2,\\n    \"embed_p\": 0.02,\\n    \"weight_p\": 0.15\\n  },\\n  \"wd\": 0.01,\\n  \"clip\": 0.12,\\n  \"label_smoothing_eps\": 0.1,\\n  \"label_smoothing_eps_norm_by_classes\": true,\\n  \"weighted_cross_entropy\": null,\\n  \"early_stopping\": null,\\n  \"fit_schedule\": \"1cycle\",\\n  \"random_init\": false,\\n  \"bptt\": 70,\\n  \"fp16\": false,\\n  \"base\": \"/content/gdrive/My Drive/multilingual toxic/es/es1\"\\n}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN1NyDNKZuYw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}