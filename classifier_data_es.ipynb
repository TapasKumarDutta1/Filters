{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier_data_es.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5WBGH3VvkIySXB7OhU7xv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/multilingial/blob/master/classifier_data_es.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtjP1obcBbL8",
        "outputId": "527797a5-99c0-4992-edc3-8ac3df440f8e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ObeBkJD06Zu",
        "outputId": "3dd2c2f5-d718-407d-c7df-6107d2f90d67"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN82VCCY1QNA",
        "outputId": "dade1bab-ef46-49a1-fc6c-45c32b15c121"
      },
      "source": [
        "pip install git+https://github.com/n-waves/multifit"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/n-waves/multifit\n",
            "  Cloning https://github.com/n-waves/multifit to /tmp/pip-req-build-0kbx14qv\n",
            "  Running command git clone -q https://github.com/n-waves/multifit /tmp/pip-req-build-0kbx14qv\n",
            "Requirement already satisfied (use --upgrade to upgrade): multifit==1.0 from git+https://github.com/n-waves/multifit in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: multifit\n",
            "  Building wheel for multifit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multifit: filename=multifit-1.0-cp36-none-any.whl size=24505 sha256=4b462a7e0b395939eb0bc10dadeb3a7e9d32258558cad1b595c3c95ba285592f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w90zdt9q/wheels/b7/92/1e/246f31a4e84fd665b5907cb96765f696be45e814ff68a5fd4a\n",
            "Successfully built multifit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVFPZy011RYp",
        "outputId": "262c31c2-f44b-4d73-d131-39c14e05cef9"
      },
      "source": [
        "pip install sacremoses"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.43)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82jsWtZA1SP6",
        "outputId": "a7a912bd-9c8d-4637-8514-931b8747978e"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqEFS1Jx1TIQ"
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppkRFLMD1xFR",
        "outputId": "f15850f7-d7d5-4478-85fc-aa5df500e93a"
      },
      "source": [
        "help(TextList.from_df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method from_df in module fastai.data_block:\n",
            "\n",
            "from_df(df:pandas.core.frame.DataFrame, path:Union[pathlib.Path, str]='.', cols:Union[int, Collection[int], str, Collection[str]]=0, processor:Union[fastai.data_block.PreProcessor, Collection[fastai.data_block.PreProcessor]]=None, **kwargs) -> 'ItemList' method of builtins.type instance\n",
            "    Create an `ItemList` in `path` from the inputs in the `cols` of `df`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uNMMBPLBlza",
        "outputId": "877f1363-fd5d-4a11-ff93-f9f9095f1ef0"
      },
      "source": [
        "import glob\r\n",
        "glob.glob('/content/gdrive/My Drive/multilingual/*')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/multilingual/jigsaw-toxic-comment-train.csv',\n",
              " '/content/gdrive/My Drive/multilingual/jigsaw-toxic-comment-train-processed-seqlen128.csv',\n",
              " '/content/gdrive/My Drive/multilingual/validation.csv',\n",
              " '/content/gdrive/My Drive/multilingual/test.csv',\n",
              " '/content/gdrive/My Drive/multilingual/submission.csv',\n",
              " '/content/gdrive/My Drive/multilingual/es']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wm5e1lpBjTX"
      },
      "source": [
        "import pandas as pd\r\n",
        "def load_data():\r\n",
        "    trn=pd.read_csv('/content/gdrive/My Drive/multilingual/jigsaw-toxic-comment-train.csv',usecols=['toxic','comment_text'])\r\n",
        "    tst=pd.read_csv('/content/gdrive/My Drive/multilingual/test.csv',usecols=['lang','content'])  \r\n",
        "    sub=pd.read_csv('/content/gdrive/My Drive/multilingual/submission.csv')  \r\n",
        "    return trn,tst,sub\r\n",
        "train,test,sub=load_data()\r\n",
        "test['toxic']=sub['toxic'].round()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtpMbQGeCBT-"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Dense, Input\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "import transformers\r\n",
        "from transformers import TFAutoModel, AutoTokenizer\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\r\n",
        "from tensorflow.keras.layers import *\r\n",
        "from fastai.text import *\r\n",
        "import multifit"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jcmqB8KgCHK3",
        "outputId": "b2ac8a74-8ec2-482e-ba7a-7c8bcab7c0ce"
      },
      "source": [
        "es=test.loc[test['lang']=='es'].reset_index(drop=True)\r\n",
        "es.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>lang</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>el skate es unos de los deportes favoritos de ...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Me doy la bienvenida. A este usuari le gusta c...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ES NOTABLEMENTE TENDENCIOSO, NO SE HABLA DE CU...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>El Jardín de infantes Nº938, fundado en 1989, ...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Daré explicaciones y/o aclaraciones a cualquie...</td>\n",
              "      <td>es</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content lang  toxic\n",
              "0  el skate es unos de los deportes favoritos de ...   es    0.0\n",
              "1  Me doy la bienvenida. A este usuari le gusta c...   es    0.0\n",
              "2  ES NOTABLEMENTE TENDENCIOSO, NO SE HABLA DE CU...   es    0.0\n",
              "3  El Jardín de infantes Nº938, fundado en 1989, ...   es    0.0\n",
              "4  Daré explicaciones y/o aclaraciones a cualquie...   es    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itanvsgaE4L-"
      },
      "source": [
        "def set_seed(seed):\r\n",
        "    if seed is not None:\r\n",
        "        torch.manual_seed(seed)\r\n",
        "        torch.backends.cudnn.deterministic = True\r\n",
        "        torch.backends.cudnn.benchmark = False\r\n",
        "        np.random.seed(seed)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "s8DbvZBPCZ_F",
        "outputId": "763e3dc1-2239-49ac-c7d4-e33122a1e9a5"
      },
      "source": [
        "exp = multifit.from_pretrained(\"es_multifit_paper_version\")\r\n",
        "tokenizer = exp.pretrain_lm.tokenizer\r\n",
        "fa_config =  tokenizer.get_fastai_config(add_open_file_processor=True)\r\n",
        "data_lm = (TextList.from_df(es, **fa_config)\r\n",
        "            .split_by_rand_pct(0.1)\r\n",
        "            .label_for_lm()           \r\n",
        "            .databunch(bs=32))\r\n",
        "exp.finetune_lm.arch.lang = 'es'\r\n",
        "set_seed(42)\r\n",
        "learn = exp.finetune_lm.get_learner(data_lm)  \r\n",
        "    # learn is a preconfigured fastai learner with a pretrained model loaded\r\n",
        "data_lm.show_batch()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training args:  {'drop_mult': 0.3, 'true_wd': False, 'wd': 1e-07, 'pretrained': False, 'clip': 0.12} config:  {'emb_sz': 400, 'n_hid': 1550, 'n_layers': 4, 'pad_token': 1, 'qrnn': True, 'bidir': False, 'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15, 'tie_weights': True, 'out_bias': True}\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Setting LM training seed seed to 0\n",
            "Loading pretrained weights:  [PosixPath('/root/.fastai/models/es_multifit_paper_version/lm_best'), PosixPath('/root/.fastai/models/es_multifit_paper_version/itos')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  idx_min = (t != self.pad_idx).nonzero().min()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>us ua ri ▁le ▁gu sta ▁confronta rse ▁con ▁los ▁ignora ntes ▁. ▁ ¿ ▁ xxmaj ▁va mos ▁a ▁estar ▁ tú ▁y ▁y o ▁de ▁acuerdo ▁o ▁no ▁ ? ▁( ▁discusión ▁) ▁18 ▁: ▁28 ▁27 ▁ dic ▁2014 ▁( ▁ xxup ▁ ut c ▁) ▁ xxbos ▁ xxfld ▁1 ▁ xxup ▁es ▁ xxup ▁notable mente ▁ xxup ▁ ten den ci oso ▁, ▁</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>n ▁de ▁eliminar lo ▁de ▁una ▁vez ▁por ▁la ▁falta ▁de ▁neutral idad ▁, ▁ vo y ▁a ▁su ger ir ▁que ▁sea ▁eliminado ▁, ▁ pond ré ▁la ▁plantilla ▁mas ▁adelante ▁, ▁no ▁se ▁ha ▁llegado ▁ni ▁ cre o ▁que ▁ lle gue n ▁a ▁acuerdo s ▁sobre ▁este ▁tema ▁y ▁deberá ▁ser ▁eliminado ▁. ▁ — ▁j ca ma cho d ▁ ¡ ▁ xxmaj ▁me xi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>▁bal dos as ▁, ▁sin ▁pi s ar ▁las ▁líneas ▁, ▁pen s ando ▁en ▁ mis ▁cosas ▁, ▁los ▁días ▁ pesa n ▁, ▁la ▁vida ▁no ▁me ▁be sa ▁, ▁los ▁días ▁que ▁pasa mos ▁juntos ▁ya ▁no ▁me ▁interesa n ▁ ” ▁. ▁ xxbos ▁ xxfld ▁1 ▁ xxmaj ▁me ▁ lla mo ▁ xxmaj ▁juan jo ▁ xxmaj ▁navarro ▁ xxmaj ▁esp ín ▁, ▁</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>▁ res ▁ha ▁ pas s at ▁ ja ▁... ▁ ja ▁ et ▁pregunta ré ▁ - ▁) ▁) ▁. ▁ xxbos ▁ xxfld ▁1 ▁a ver ▁para ▁todos ▁los ▁pen de jos ▁que ▁se ▁sabe n ▁hacer ▁su ▁wi ki cor reo ▁entonces ▁esta n ▁b n ▁ ton tos ▁ xxup ▁pen de jos ▁ xxup ▁a tte ▁: ▁ xxup ▁ bran don ▁ xxup ▁</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>▁un ▁movimiento ▁mal is o cio ▁que ▁tienen ▁de ▁cop y ▁pa ge . ▁y ▁los ▁encontrar as ▁por ▁todos ▁la dos ▁en ▁la ▁red ▁, ▁lo ▁que ▁me ▁di go ▁como ▁pierde n ▁su ▁tiempo ▁, ▁mejor ▁lo ▁debería n ▁de ▁emplea r ▁en ▁cosas ▁ positivas ▁y ▁mejorar ▁sus ▁vida s ▁. ▁ xxmaj ▁son ▁las ▁mismas ▁organizaciones ▁vincula das ▁en ▁ xxmaj ▁asesinato ▁motiv ados ▁por ▁los</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDNDj3MNB9mA"
      },
      "source": [
        "# learn.freeze_to(-1)\r\n",
        "# learn.fit_one_cycle(1, 1e-4 * 10, moms=(0.8, 0.7))\r\n",
        "# learn.unfreeze()\r\n",
        "# learn.fit_one_cycle(10, 1e-4, moms=(0.8, 0.7))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRydnRKIMWKC"
      },
      "source": [
        "path='/content/gdrive/My Drive/multilingual toxic/es/es1'\r\n",
        "self=exp.finetune_lm\r\n",
        "CLS_BEST = path+'/cls_best1'\r\n",
        "LM_BEST = path+\"/lm_best1\"\r\n",
        "ENC_BEST = path+\"/enc_best1\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj4uCxyr3kXn",
        "outputId": "cbbf03a7-4cc7-4dbe-a987-f4d5df8d2ee9"
      },
      "source": [
        "path='/content/gdrive/My Drive/multilingual toxic/es/es1'\r\n",
        "self=exp.finetune_lm\r\n",
        "CLS_BEST = path+'/cls_best'\r\n",
        "LM_BEST = path+\"/lm_best\"\r\n",
        "ENC_BEST = path+\"/enc_best\"\r\n",
        "\r\n",
        "\r\n",
        "experiment_path=Path(path)\r\n",
        "self.experiment_path=experiment_path\r\n",
        "print(\"Experiment\", experiment_path)\r\n",
        "\r\n",
        "#save tokenizer\r\n",
        "tokenizer.save(self.experiment_path, learn=learn)\r\n",
        "learn.to_fp32()\r\n",
        "#save encoder weights to (ENC_BEST,learn.path,learn.model_dir)\r\n",
        "learn.save_encoder(ENC_BEST)\r\n",
        "#save model structure to (LM_BEST, learn.path,learn.model_dir,'.pth')\r\n",
        "learn.save(LM_BEST, with_opt=False)\r\n",
        "# learn.destroy()\r\n",
        "# saving 'seed', 'name', 'arch', 'experiment_path', 'dataset_path', 'num_epochs', 'bs', 'bptt', 'drop_mult', 'dropout_values', 'label_smoothing_eps', 'label_smoothing_eps_norm_by_classes', 'use_adam_08', 'true_wd', 'wd', 'clip', 'fp16', 'lr', 'base' \r\n",
        "# to /content/gdrive/My Drive/multilingual toxic/es/es1/finetuning.json\r\n",
        "# save_paramters(self)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment /content/gdrive/My Drive/multilingual toxic/es/es1\n",
            "Copy sp model from /root/.fastai/models/es_multifit_paper_version to /content/gdrive/My Drive/multilingual toxic/es/es1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "0uTQR6_sRFsP",
        "outputId": "54cc3cfc-650b-4f97-feac-869288acad2f"
      },
      "source": [
        "self=exp.classifier\r\n",
        "es['toxic']=es['toxic'].astype(np.long)\r\n",
        "from pathlib import Path\r\n",
        "data_clas = TextClasDataBunch.from_df(\"\", es.loc[1000:].reset_index(drop=True),es[:1000],  text_cols = 'content', label_cols = 'toxic',bs=64,vocab=data_lm.vocab)\r\n",
        "data_clas.vocab.itos = data_lm.vocab.itos\r\n",
        "l1rn = exp.classifier.get_learner(data_clas)  \r\n",
        "# learn is a preconfigured fastai learner with a pretrained model loaded\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using Label smoothing with eps =  0.05\n",
            "Setting Classifier weights seed seed to 0\n",
            "Training args:  {'drop_mult': 0.5, 'wd': 0.01, 'pretrained': False, 'bptt': 70, 'loss_func': FlattenedLoss of LabelSmoothingCrossEntropy(), 'clip': 0.12, 'silent': False} config:  {'emb_sz': 400, 'n_hid': 1550, 'n_layers': 4, 'pad_token': 1, 'qrnn': True, 'bidir': False, 'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15}\n",
            "Loading pretrained model /content/gdrive/My Drive/multilingual toxic/es/es1/enc_best\n",
            "Setting Classifier training seed seed to 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAHNpCK0Wj6N"
      },
      "source": [
        "l1rn.unfreeze()\r\n",
        "def _fit_schedule_1cycle(num_epochs, learn):\r\n",
        "        learn.unfreeze()\r\n",
        "        learn.fit_one_cycle(num_epochs, slice(1e-2 / (2.6 ** 4), 2e-2), moms=(0.8, 0.7))\r\n",
        "\r\n",
        "def _fit_schedule_layered(num_epochs, learn):\r\n",
        "        learn.freeze_to(-1)\r\n",
        "        learn.fit_one_cycle(1, 2e-2, moms=(0.8, 0.7))\r\n",
        "        if num_epochs > 1:\r\n",
        "            learn.freeze_to(-2)\r\n",
        "            learn.fit_one_cycle(1, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7))\r\n",
        "            learn.freeze_to(-3)\r\n",
        "            learn.fit_one_cycle(1, slice(5e-3 / (2.6 ** 4), 5e-3), moms=(0.8, 0.7))\r\n",
        "            learn.unfreeze()\r\n",
        "        if num_epochs > 5:\r\n",
        "            learn.fit_one_cycle(num_epochs - 4, slice(1e-3 / (2.6 ** 4), 1e-3), moms=(0.8, 0.7))\r\n",
        "\r\n",
        "def _fit_schedule_2cycle(num_epochs, learn):\r\n",
        "        learn.freeze_to(-1)\r\n",
        "        learn.fit_one_cycle(1, 2e-2, moms=(0.8, 0.7))\r\n",
        "        learn.unfreeze()\r\n",
        "        if num_epochs > 1:\r\n",
        "            learn.fit_one_cycle(num_epochs - 1, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7))\r\n",
        "\r\n",
        "def _fit_schedule_reverse_2cycle(num_epochs, learn):\r\n",
        "        learn.unfreeze()\r\n",
        "        for g in learn.layer_groups[-1:]:\r\n",
        "            for l in g:\r\n",
        "                if not learn.train_bn or not isinstance(l, bn_types): requires_grad(l, False)\r\n",
        "        learn.create_opt(defaults.lr)\r\n",
        "        learn.fit_one_cycle(num_epochs, slice(1e-2 / (2.6 ** 4), 2e-2), moms=(0.8, 0.7))\r\n",
        "        learn.unfreeze()\r\n",
        "        learn.fit_one_cycle(num_epochs, slice(1e-3 / (2.6 ** 4), 2e-3), moms=(0.8, 0.7))\r\n",
        "\r\n",
        "def _fit_schedule_false_wd(self, learn):\r\n",
        "        learn.true_wd = False\r\n",
        "        learn.fit_one_cycle(1, 5e-2, moms=(0.8, 0.7), wd=1e-7)\r\n",
        "        if num_epochs > 1:\r\n",
        "            learn.freeze_to(-2)\r\n",
        "            learn.fit_one_cycle(1, slice(5e-2 / (2.6 ** 4), 5e-2), moms=(0.8, 0.7), wd=1e-7)\r\n",
        "            learn.freeze_to(-3)\r\n",
        "            learn.fit_one_cycle(1, slice(5e-4 / (2.6 ** 4), 5e-4), moms=(0.8, 0.7), wd=1e-7)\r\n",
        "            learn.unfreeze()\r\n",
        "            if num_epochs > 5:\r\n",
        "                learn.fit_one_cycle(num_epochs - 4, slice(1e-2 / (2.6 ** 4), 1e-2), moms=(0.8, 0.7), wd=1e-7)\r\n",
        "\r\n",
        "# _fit_schedule_1cycle(10,l1rn)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "VVVyTyAoWn3W",
        "outputId": "42135dd0-ba39-4248-c85b-321b6fb45028"
      },
      "source": [
        "self.experiment_path = l1rn.path / l1rn.model_dir\r\n",
        "tokenizer.save(self.experiment_path, learn=l1rn)\r\n",
        "l1rn.to_fp32()\r\n",
        "l1rn.save(CLS_BEST, with_opt=False)\r\n",
        "print(\"Classifier model saved to\", self.experiment_path)\r\n",
        "self.save_paramters()\r\n",
        "        # learn.destroy()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copy sp model from /root/.fastai/models/es_multifit_paper_version to multifit_paper_version\n",
            "Classifier model saved to multifit_paper_version\n",
            "Saving dump to multifit_paper_version/classifier.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\\n  \"seed\": 0,\\n  \"name\": \"multifit_paper_version\",\\n  \"arch\": {\\n    \"tokenizer_type\": \"sp\",\\n    \"max_vocab\": 15000,\\n    \"lang\": \"es\",\\n    \"emb_sz\": 400,\\n    \"n_hid\": 1550,\\n    \"n_layers\": 4,\\n    \"qrnn\": true\\n  },\\n  \"experiment_path\": \"multifit_paper_version\",\\n  \"dataset_path\": null,\\n  \"bs\": 18,\\n  \"num_epochs\": 8,\\n  \"drop_mult\": 0.5,\\n  \"dropout_values\": {\\n    \"output_p\": 0.25,\\n    \"hidden_p\": 0.1,\\n    \"input_p\": 0.2,\\n    \"embed_p\": 0.02,\\n    \"weight_p\": 0.15\\n  },\\n  \"wd\": 0.01,\\n  \"clip\": 0.12,\\n  \"label_smoothing_eps\": 0.1,\\n  \"label_smoothing_eps_norm_by_classes\": true,\\n  \"weighted_cross_entropy\": null,\\n  \"early_stopping\": null,\\n  \"fit_schedule\": \"1cycle\",\\n  \"random_init\": false,\\n  \"bptt\": 70,\\n  \"fp16\": false,\\n  \"base\": \"/content/gdrive/My Drive/multilingual toxic/es/es1\"\\n}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN1NyDNKZuYw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}