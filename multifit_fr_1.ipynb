{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multifit_fr_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/multilingial/blob/master/multifit_fr_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zg7Z1MxwxST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtuVe1YOZSm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2idGzXgEV5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install git+https://github.com/n-waves/multifit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4YeJJ3DE2YA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install sacremoses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYSglC4GCBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apj6OOR7JtnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile \n",
        "path = F\"/content/gdrive/My Drive/multilingual toxic/\" \n",
        "with ZipFile(path+'toxic.zip', 'r') as zip: \n",
        "    # printing all the contents of the zip file \n",
        "    zip.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    zip.extractall() \n",
        "    print('Done!')\n",
        "import pandas as pd\n",
        "def load_data():\n",
        "    trn=pd.read_csv('jigsaw-toxic-comment-train.csv',usecols=['toxic','comment_text'])\n",
        "    val=pd.read_csv('validation.csv',usecols=['toxic','comment_text','lang'])\n",
        "    tst=pd.read_csv('test.csv',usecols=['lang','content'])  \n",
        "    sub=pd.read_csv('submission (1).csv')  \n",
        "    return trn,tst,val,sub\n",
        "train,test,valid,sub=load_data()\n",
        "test['toxic']=sub['toxic'].round()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OZ0ykdiRV6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train.shape,test.shape,valid.shape,sub.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvS019LgKbjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import transformers\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
        "from tensorflow.keras.layers import *\n",
        "from fastai.text import *\n",
        "import multifit\n",
        "exp = multifit.from_pretrained(\"es_multifit_paper_version\")\n",
        "def regular_encode(texts, tokenizer, maxlen=512):\n",
        "    enc_di = tokenizer.batch_encode_plus(\n",
        "        texts, \n",
        "        return_attention_masks=False, \n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=maxlen\n",
        "    )\n",
        "    \n",
        "    return np.array(enc_di['input_ids'])\n",
        "fa_config =  exp.pretrain_lm.tokenizer.get_fastai_config(add_open_file_processor=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEikVSPlQkGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es=test.loc[test['lang']=='fr']\n",
        "es['id']=es.index\n",
        "es=es.reset_index(drop=True)\n",
        "es.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvuqbUaHZtUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeJdr-HQA_BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es['toxic']=es['toxic'].astype(np.long)\n",
        "ln=es.shape[0]//5\n",
        "trn=es.loc[ln:]\n",
        "val=es.loc[:ln]\n",
        "print(trn.shape,val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4eDzDHjY77y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "    exp = multifit.from_pretrained(\"fr_multifit_paper_version\")\n",
        "    fa_config =  exp.pretrain_lm.tokenizer.get_fastai_config(add_open_file_processor=True)\n",
        "    data_lm = (TextList.from_df(es, **fa_config)\n",
        "            .split_by_rand_pct(0.1)\n",
        "            .label_for_lm()           \n",
        "            .databunch(bs=32))\n",
        "    learn = exp.finetune_lm.get_learner(data_lm)  \n",
        "    # learn is a preconfigured fastai learner with a pretrained model loaded\n",
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvpq-DCgA3od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(10,max_lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2RkUhVOVK6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "self=exp.finetune_lm\n",
        "CLS_BEST = 'cls_best'\n",
        "LM_BEST = \"lm_best\"\n",
        "ENC_BEST = \"enc_best\"\n",
        "experiment_path=Path(path)\n",
        "self.experiment_path=experiment_path\n",
        "tokenizer = self.base.tokenizer\n",
        "print(\"Experiment\", experiment_path)\n",
        "\n",
        "self.experiment_path = experiment_path\n",
        "tokenizer.save(self.experiment_path, learn=learn)\n",
        "learn.to_fp32()\n",
        "learn.save_encoder('/content/'+ENC_BEST)\n",
        "learn.save(LM_BEST, with_opt=False)\n",
        "# learn.destroy()\n",
        "self.save_paramters()\n",
        "print(\"Language model saved to\", self.experiment_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHv5lf-Th88k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "self=exp.classifier\n",
        "self.base.experiment_path=Path('')\n",
        "from pathlib import Path\n",
        "with strategy.scope():\n",
        "    exp.classifier.experiment_path=Path('')\n",
        "    data_clas = TextClasDataBunch.from_df(\"\", trn.reset_index(drop=True),val,  text_cols = 'content', label_cols = 'toxic',bs=32,vocab=data_lm.vocab)\n",
        "    data_clas.vocab.itos = data_lm.vocab.itos\n",
        "    l1rn = exp.classifier.get_learner(data_clas)  \n",
        "# learn is a preconfigured fastai learner with a pretrained model loaded\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysPVBeGziCCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8oz3uSbiDJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1rn.fit_one_cycle(10,max_lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07KUT8p1B370",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre=l1rn.get_preds()[0][:,1].reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oViudYCCBpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val['toxic']=np.asarray(pre)\n",
        "val.to_csv(path+'fr_1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}