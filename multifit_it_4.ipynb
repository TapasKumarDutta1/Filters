{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multifit_it_4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/multilingial/blob/master/multifit_it_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zg7Z1MxwxST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "e3e5c9e6-6efb-4f6c-bced-921fe216d469"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtuVe1YOZSm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "39950c24-600c-40fe-96c6-bd0b756b343c"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 3.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=5a5aeb830734b2ddfe9309ac75651d07524023cdfc40c6531defe9bbe888e61e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2idGzXgEV5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2b19b3a8-da2c-492f-b892-bf010e1cc0c5"
      },
      "source": [
        "pip install git+https://github.com/n-waves/multifit"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/n-waves/multifit\n",
            "  Cloning https://github.com/n-waves/multifit to /tmp/pip-req-build-jmtgu56m\n",
            "  Running command git clone -q https://github.com/n-waves/multifit /tmp/pip-req-build-jmtgu56m\n",
            "Building wheels for collected packages: multifit\n",
            "  Building wheel for multifit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multifit: filename=multifit-1.0-cp36-none-any.whl size=24506 sha256=e23ce67bffff69b70115d4f1cc0b93a5d734903f513f29874bdaeb4183115c41\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lkek3izc/wheels/b7/92/1e/246f31a4e84fd665b5907cb96765f696be45e814ff68a5fd4a\n",
            "Successfully built multifit\n",
            "Installing collected packages: multifit\n",
            "Successfully installed multifit-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4YeJJ3DE2YA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "87588cec-67d6-4fc9-afe2-861906dae839"
      },
      "source": [
        "pip install sacremoses"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYSglC4GCBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7dfb46bf-923f-4821-a373-1a12be1632cc"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apj6OOR7JtnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "c438ba0a-d5f0-435e-9b0e-ffecec3ed547"
      },
      "source": [
        "from zipfile import ZipFile \n",
        "path = F\"/content/gdrive/My Drive/multilingual toxic/\" \n",
        "with ZipFile(path+'toxic.zip', 'r') as zip: \n",
        "    # printing all the contents of the zip file \n",
        "    zip.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    zip.extractall() \n",
        "    print('Done!')\n",
        "import pandas as pd\n",
        "def load_data():\n",
        "    trn=pd.read_csv('jigsaw-toxic-comment-train.csv',usecols=['toxic','comment_text'])\n",
        "    val=pd.read_csv('validation.csv',usecols=['toxic','comment_text','lang'])\n",
        "    tst=pd.read_csv('test.csv',usecols=['lang','content'])  \n",
        "    sub=pd.read_csv('submission (1).csv')  \n",
        "    return trn,tst,val,sub\n",
        "train,test,valid,sub=load_data()\n",
        "test['toxic']=sub['toxic'].round()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Name                                             Modified             Size\n",
            "jigsaw-toxic-comment-train.csv                 2020-06-08 23:38:40     95538001\n",
            "test.csv                                       2020-06-08 23:39:02     28783206\n",
            "validation.csv                                 2020-06-08 23:38:52      3178555\n",
            "submission (1).csv                             2020-06-08 23:50:22      1161879\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OZ0ykdiRV6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "29a1287f-6108-4df2-a204-c383193d7d58"
      },
      "source": [
        "print(train.shape,test.shape,valid.shape,sub.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(223549, 2) (63812, 3) (8000, 3) (63812, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvS019LgKbjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "23424be7-4c78-4afd-e97f-db4bbcb35c0a"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import transformers\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
        "from tensorflow.keras.layers import *\n",
        "from fastai.text import *\n",
        "import multifit\n",
        "exp = multifit.from_pretrained(\"es_multifit_paper_version\")\n",
        "def regular_encode(texts, tokenizer, maxlen=512):\n",
        "    enc_di = tokenizer.batch_encode_plus(\n",
        "        texts, \n",
        "        return_attention_masks=False, \n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=maxlen\n",
        "    )\n",
        "    \n",
        "    return np.array(enc_di['input_ids'])\n",
        "fa_config =  exp.pretrain_lm.tokenizer.get_fastai_config(add_open_file_processor=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/n-waves/multifit-models/releases/download/es_multifit_paper_version/es_multifit_paper_version.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEikVSPlQkGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "2b712486-0c30-49cf-b08a-6cb761355b5e"
      },
      "source": [
        "es=test.loc[test['lang']=='it']\n",
        "es['id']=es.index\n",
        "es=es.reset_index(drop=True)\n",
        "es.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>lang</th>\n",
              "      <th>toxic</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
              "      <td>it</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>... mumble.... mumble..... per la riforma di A...</td>\n",
              "      <td>it</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ciao demente, 6 tu lo stronzo che mi hai blocc...</td>\n",
              "      <td>it</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>l aggiornamento dovrebbe in realtà riguardare ...</td>\n",
              "      <td>it</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Auguri per Natale =)    Erik91   ☆☆☆  Auguri (...</td>\n",
              "      <td>it</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content lang  toxic  id\n",
              "0  Quindi tu sei uno di quelli   conservativi  , ...   it    0.0   2\n",
              "1  ... mumble.... mumble..... per la riforma di A...   it    0.0  46\n",
              "2  ciao demente, 6 tu lo stronzo che mi hai blocc...   it    1.0  64\n",
              "3  l aggiornamento dovrebbe in realtà riguardare ...   it    0.0  71\n",
              "4  Auguri per Natale =)    Erik91   ☆☆☆  Auguri (...   it    0.0  76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvuqbUaHZtUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "outputId": "6d3f91fd-d5be-41ee-9c2f-245d7da9f9ab"
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.96.198.42:8470\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.96.198.42:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.96.198.42:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeJdr-HQA_BX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "971e359c-1801-4ba5-9f51-b415814b3f9c"
      },
      "source": [
        "es['toxic']=es['toxic'].astype(np.long)\n",
        "ln=es.shape[0]//5\n",
        "trn=pd.concat([es.loc[:3*ln],es.loc[4*ln:]],0).reset_index(drop=True)\n",
        "val=es.loc[3*ln:4*ln].reset_index(drop=True)\n",
        "print(trn.shape,val.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6797, 4) (1699, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4eDzDHjY77y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "57545e9f-2496-4fad-d54b-51148b776e02"
      },
      "source": [
        "with strategy.scope():\n",
        "    exp = multifit.from_pretrained(\"fr_multifit_paper_version\")\n",
        "    fa_config =  exp.pretrain_lm.tokenizer.get_fastai_config(add_open_file_processor=True)\n",
        "    data_lm = (TextList.from_df(es, **fa_config)\n",
        "            .split_by_rand_pct(0.1)\n",
        "            .label_for_lm()           \n",
        "            .databunch(bs=32))\n",
        "    learn = exp.finetune_lm.get_learner(data_lm)  \n",
        "    # learn is a preconfigured fastai learner with a pretrained model loaded\n",
        "data_lm.show_batch()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/n-waves/multifit-models/releases/download/fr_multifit_paper_version/fr_multifit_paper_version.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training args:  {'drop_mult': 0.3, 'true_wd': False, 'wd': 1e-07, 'pretrained': False, 'clip': 0.12} config:  {'emb_sz': 400, 'n_hid': 1550, 'n_layers': 4, 'pad_token': 1, 'qrnn': True, 'bidir': False, 'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15, 'tie_weights': True, 'out_bias': True}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
            "  \"Distutils was imported before Setuptools. This usage is discouraged \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Setting LM training seed seed to 0\n",
            "Loading pretrained weights:  [PosixPath('/root/.fastai/models/fr_multifit_paper_version/lm_best'), PosixPath('/root/.fastai/models/fr_multifit_paper_version/itos')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  idx_min = (t != self.pad_idx).nonzero().min()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>wo r l d bir d na mes . or g ▁/ ▁ up da tes ▁/ ▁ ta x on o my ▁/ ▁ xxmaj ▁ad ▁un a ▁prima ▁ oc chi ata ▁le ▁ nov it à ▁pi ù ▁so s tan zi ali ▁ ri gu ard ano ▁ xxmaj ▁bu cer ot idae ▁ e ▁ xxmaj ▁ ic ter idae ▁. ▁ xxmaj ▁ dia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>xxmaj ▁qu ella ▁d ella ▁ nas ci ta ▁de l ▁nu o vo ▁mar chi o ▁( ▁conc or rent e ▁) ▁di ▁ xxmaj ▁giovanni ▁ xxmaj ▁a can for a ▁si ▁pu ò ▁tro var e ▁ nel ▁si to ▁ xxmaj ▁gi vo va . it ▁, ▁con ▁relativ a ▁d ata ▁di ▁ nas ci ta ▁. ▁ xxmaj ▁ s iste ma ▁la ▁</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>a ▁ ? ▁ xxmaj ▁se r gio ▁ e ▁maria nom e dia ▁: ▁ xxmaj ▁ es e mp io . o gg ▁ xxbos ▁ xxfld ▁1 ▁ xxmaj ▁la ▁ wiki ▁in ▁ lin gua ▁ te des ca ▁la ▁pen sa ▁co s ì ▁, ▁tant ▁ è ▁ver o ▁ che ▁ rec ita ▁: ▁ xxmaj ▁ba ar ▁( ▁ xxmaj ▁schw a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>bb ero ▁per cu o ter vi ▁le ▁ gin oc chi a ▁con ▁un ▁manga n ello ▁di ▁to fu ▁. ▁ xxmaj ▁ho ▁bloc ca to ▁l ▁ ut ent e ▁qui ▁ s op ra ▁per ▁ off es e ▁. ▁ xxmaj ▁son o ▁sta to ▁for s e ▁ ec ces s ivo ▁ ? ▁ xxmaj ▁di ▁nul la . ▁ cia o ▁</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>e ▁ nas con de ▁la ▁ s ua ▁ ide nt it à ▁, ▁ma ▁vol e te ▁imp or re ▁un a ▁co er ci zio ne ▁ s ul la ▁vol nt à ▁ e ▁il ▁di rit to ▁di ▁auto de ter mina zio ne ▁d ella ▁d ir etta ▁inter es s ata . la ▁in vit o ▁a ▁for ni re ▁ xxup ▁il</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvpq-DCgA3od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8bc11b9c-f783-438c-bd6f-884c087ef206"
      },
      "source": [
        "learn.fit_one_cycle(10,max_lr=1e-4)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>8.527474</td>\n",
              "      <td>5.804018</td>\n",
              "      <td>0.174238</td>\n",
              "      <td>48:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>8.303935</td>\n",
              "      <td>5.618890</td>\n",
              "      <td>0.187150</td>\n",
              "      <td>48:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>7.652603</td>\n",
              "      <td>5.368293</td>\n",
              "      <td>0.202912</td>\n",
              "      <td>48:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>7.149522</td>\n",
              "      <td>5.133630</td>\n",
              "      <td>0.211126</td>\n",
              "      <td>48:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>6.860174</td>\n",
              "      <td>4.963710</td>\n",
              "      <td>0.222754</td>\n",
              "      <td>48:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>6.466130</td>\n",
              "      <td>4.836970</td>\n",
              "      <td>0.234973</td>\n",
              "      <td>48:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>6.452240</td>\n",
              "      <td>4.742948</td>\n",
              "      <td>0.239657</td>\n",
              "      <td>48:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>6.483676</td>\n",
              "      <td>4.695785</td>\n",
              "      <td>0.241985</td>\n",
              "      <td>48:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>6.301716</td>\n",
              "      <td>4.676025</td>\n",
              "      <td>0.242630</td>\n",
              "      <td>48:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>6.379739</td>\n",
              "      <td>4.674393</td>\n",
              "      <td>0.242624</td>\n",
              "      <td>48:35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2RkUhVOVK6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "3eba1d33-6216-497e-cc00-e01faeb834cb"
      },
      "source": [
        "self=exp.finetune_lm\n",
        "CLS_BEST = 'cls_best'\n",
        "LM_BEST = \"lm_best\"\n",
        "ENC_BEST = \"enc_best\"\n",
        "experiment_path=Path(path)\n",
        "self.experiment_path=experiment_path\n",
        "tokenizer = self.base.tokenizer\n",
        "print(\"Experiment\", experiment_path)\n",
        "\n",
        "self.experiment_path = experiment_path\n",
        "tokenizer.save(self.experiment_path, learn=learn)\n",
        "learn.to_fp32()\n",
        "learn.save_encoder('/content/'+ENC_BEST)\n",
        "learn.save(LM_BEST, with_opt=False)\n",
        "# learn.destroy()\n",
        "self.save_paramters()\n",
        "print(\"Language model saved to\", self.experiment_path)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment /content/gdrive/My Drive/multilingual toxic\n",
            "Copy sp model from /root/.fastai/models/fr_multifit_paper_version to /content/gdrive/My Drive/multilingual toxic\n",
            "Saving dump to /content/gdrive/My Drive/multilingual toxic/finetuning.json\n",
            "Language model saved to /content/gdrive/My Drive/multilingual toxic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHv5lf-Th88k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "48bd54e1-d4fb-4c01-bbd6-78766ea73f1d"
      },
      "source": [
        "self=exp.classifier\n",
        "self.base.experiment_path=Path('')\n",
        "from pathlib import Path\n",
        "with strategy.scope():\n",
        "    exp.classifier.experiment_path=Path('')\n",
        "    data_clas = TextClasDataBunch.from_df(\"\", trn.reset_index(drop=True),val,  text_cols = 'content', label_cols = 'toxic',bs=32,vocab=data_lm.vocab)\n",
        "    data_clas.vocab.itos = data_lm.vocab.itos\n",
        "    l1rn = exp.classifier.get_learner(data_clas)  \n",
        "# learn is a preconfigured fastai learner with a pretrained model loaded\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using Label smoothing with eps =  0.05\n",
            "Setting Classifier weights seed seed to 0\n",
            "Training args:  {'drop_mult': 0.5, 'wd': 0.01, 'pretrained': False, 'bptt': 70, 'loss_func': FlattenedLoss of LabelSmoothingCrossEntropy(), 'clip': 0.12, 'silent': False} config:  {'emb_sz': 400, 'n_hid': 1550, 'n_layers': 4, 'pad_token': 1, 'qrnn': True, 'bidir': False, 'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15}\n",
            "Loading pretrained model /content/enc_best\n",
            "Setting Classifier training seed seed to 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysPVBeGziCCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "eb2dc997-a021-44d6-9e98-3171bfcd3ffb"
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxup xxunk xxup di xxup xxunk ? xxup xxunk e ? xxup ma xxup xxunk xxup xxunk xxup xxunk xxup le xxup xxunk e xxup xxunk xxup xxunk xxup xxunk xxup xxunk xxup xxunk xxup zz / xxup xxunk ! xxup xxunk xxup il xxup xxunk : xxup xxunk xxup non xxup mi xxup xxunk xxup xxunk xxup che xxup su xxup wiki xxup france xxup xxunk xxup xxunk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxup hai xxup xxunk xxmaj xxunk xxunk xxunk xxunk a xxunk xxunk xxunk xxunk : xxmaj xxunk xxunk di xxunk xxunk , xxunk , xxunk . xxmaj il xxunk xxunk xxunk per un xxunk di 6 xxunk . xxmaj xxunk il xxunk xxunk , xxunk xxunk di xxunk per xxunk , xxunk xxunk le xxunk xxunk xxunk xxunk , xxunk . xxup non xxup ho xxup xxunk xxup xxunk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxup mi xxup xxunk xxup ma i xxup xxunk xxup xxunk xxup xxunk xxup xxunk xxup xxunk xxup xxunk xxunk xxup xxunk xxup xxunk l xxup xxunk xxunk xxup il xxup xxunk xxup del xxup xxunk xxup xxunk xxup per xxup xxunk xxup di xxup xxunk xxup xxunk xxup nel xxup xxunk xxup xxunk xxup xxunk xxup in xxup xxunk xxup per xxup xxunk xxunk xxup far xxup xxunk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj xxunk , xxunk io xxunk xxrep 4 . xxunk xxunk xxunk xxunk , e ti xxunk che i xxunk xxunk xxunk e xxunk xxunk xxunk me il xxunk . xxmaj xxunk , xxunk xxunk xxunk xxunk , ma si xxunk xxunk di xxunk parole ed xxunk , ma xxunk a che xxunk con il xxunk ed il xxunk . xxmaj nel xxunk di xxmaj xxunk xxunk , il</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxunk ma xxunk xxunk ti xxunk xxunk xxunk xxunk xxunk di xxmaj villa d xxmaj xxunk e non xxunk xxunk xxunk alla xxunk di xxunk xxunk xxunk xxunk dio xxunk xxunk non xxunk xxunk che xxunk tu xxunk ma una xxunk me la xxunk xxunk xxunk i xxunk xxunk a xxunk xxunk la xxunk in xxunk non ti xxunk . xxmaj non xxunk xxunk xxunk a xxmaj villa d</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8oz3uSbiDJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "5d36ef84-b8c0-49a2-d032-83de67df8f02"
      },
      "source": [
        "l1rn.fit_one_cycle(10,max_lr=1e-3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.644547</td>\n",
              "      <td>0.660483</td>\n",
              "      <td>0.620365</td>\n",
              "      <td>10:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.511221</td>\n",
              "      <td>0.420246</td>\n",
              "      <td>0.857563</td>\n",
              "      <td>09:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.443765</td>\n",
              "      <td>0.413092</td>\n",
              "      <td>0.860506</td>\n",
              "      <td>09:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.446350</td>\n",
              "      <td>0.417392</td>\n",
              "      <td>0.859918</td>\n",
              "      <td>09:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.433795</td>\n",
              "      <td>0.410076</td>\n",
              "      <td>0.858740</td>\n",
              "      <td>09:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.430860</td>\n",
              "      <td>0.413928</td>\n",
              "      <td>0.859918</td>\n",
              "      <td>09:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.434755</td>\n",
              "      <td>0.405057</td>\n",
              "      <td>0.858740</td>\n",
              "      <td>09:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.427215</td>\n",
              "      <td>0.408948</td>\n",
              "      <td>0.859918</td>\n",
              "      <td>08:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.428069</td>\n",
              "      <td>0.408237</td>\n",
              "      <td>0.859329</td>\n",
              "      <td>10:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.428650</td>\n",
              "      <td>0.409465</td>\n",
              "      <td>0.859918</td>\n",
              "      <td>10:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07KUT8p1B370",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "39dfd7a4-243a-4763-9620-a91bcd4f4ed3"
      },
      "source": [
        "pre=l1rn.get_preds()[0][:,1].reshape(-1,1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oViudYCCBpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val['toxic']=np.asarray(pre)\n",
        "val.to_csv(path+'it_4.csv')"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}