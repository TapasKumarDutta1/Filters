{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spanish_first.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwR5cUuZr9x/xN+qBhbmrF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "118b62d649fa469c82d291eb8fb2573f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8863fc4089f3460087bd04de7e1b1098",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac1ebd16cd7b44de8a9c9f5beb94077c",
              "IPY_MODEL_84ff9550dbd54a1caf68d95245809fdf"
            ]
          }
        },
        "8863fc4089f3460087bd04de7e1b1098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac1ebd16cd7b44de8a9c9f5beb94077c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f74017fbaec14ba1bbe24e3507c9ee6f",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 342,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38f90f58c65e4d54bf00d7a5fada5d4e"
          }
        },
        "84ff9550dbd54a1caf68d95245809fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_691db5f75348412d8802645e2a627d9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/342 [00:41&lt;3:56:50, 41.67s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e966d6b016a0441d9eb8125176fae43e"
          }
        },
        "f74017fbaec14ba1bbe24e3507c9ee6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38f90f58c65e4d54bf00d7a5fada5d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "691db5f75348412d8802645e2a627d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e966d6b016a0441d9eb8125176fae43e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/multilingial/blob/master/spanish_first.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utc1m9Sh3-Gs",
        "outputId": "5d92c821-6630-4a52-fbc5-1320032c7cb8"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Kbsp-m4DOS",
        "outputId": "a3b22623-4a01-4ac3-e631-ae15a1e40388"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.1)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaSmfAuO8G5R"
      },
      "source": [
        "import gc\r\n",
        "import os\r\n",
        "import time\r\n",
        "import math\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from datetime import date\r\n",
        "from transformers import *\r\n",
        "from sklearn.metrics import *\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.utils.data\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "from torch import Tensor\r\n",
        "from torch.optim import *\r\n",
        "from torch.nn.modules.loss import *\r\n",
        "from torch.optim.lr_scheduler import * \r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torch.utils.data.sampler import RandomSampler"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U8eO_Pz4LNX"
      },
      "source": [
        "import pandas as pd\r\n",
        "def load_data():\r\n",
        "    trn=pd.read_csv('/content/gdrive/My Drive/multilingual/jigsaw-toxic-comment-train.csv.zip',usecols=['toxic','comment_text'])\r\n",
        "    tst=pd.read_csv('/content/gdrive/My Drive/multilingual/test.csv.zip',usecols=['lang','content'])  \r\n",
        "    sub=pd.read_csv('/content/gdrive/My Drive/multilingual/submission.csv')\r\n",
        "    val=pd.read_csv( '/content/gdrive/My Drive/multilingual/validation.csv.zip')  \r\n",
        "    return trn,tst,sub,val\r\n",
        "\r\n",
        "\r\n",
        "def get_lang(val,tst,lang):\r\n",
        "  df=pd.concat([val,tst],0)\r\n",
        "  return df.loc[df['lang']==lang].reset_index(drop=True).drop(['id','lang'],1)\r\n",
        "\r\n",
        "\r\n",
        "def regular_encode(texts, tokenizer, maxlen=512):\r\n",
        "    enc_di = tokenizer.batch_encode_plus(\r\n",
        "        texts, \r\n",
        "        return_token_type_ids=False,\r\n",
        "        pad_to_max_length=True,\r\n",
        "        max_length=maxlen\r\n",
        "    )\r\n",
        "    \r\n",
        "    return np.array(enc_di['input_ids'])\r\n",
        "\r\n",
        "\r\n",
        "train,test,sub,val=load_data()\r\n",
        "test.columns=['comment_text','lang']\r\n",
        "test['toxic']=sub['toxic']\r\n",
        "df=get_lang(val,test,'es')\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn5B5wzm5lST"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\r\n",
        "import torch.nn as nn\r\n",
        "class Transformer(nn.Module):\r\n",
        "    def __init__(self, transformer, num_classes=1):\r\n",
        "        \"\"\"\r\n",
        "        Constructor\r\n",
        "        \r\n",
        "        Arguments:\r\n",
        "            model {string} -- Transformer to build the model on. Expects \"camembert-base\".\r\n",
        "            num_classes {int} -- Number of classes (default: {1})\r\n",
        "        \"\"\"\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.transformer = transformer\r\n",
        "\r\n",
        "        self.nb_features = self.transformer.pooler.dense.out_features\r\n",
        "\r\n",
        "        self.pooler = nn.Sequential(\r\n",
        "            nn.Linear(self.nb_features, self.nb_features), \r\n",
        "            nn.Sigmoid(),\r\n",
        "        )\r\n",
        "\r\n",
        "        self.logit = nn.Linear(self.nb_features, num_classes)\r\n",
        "\r\n",
        "    def forward(self, tokens):\r\n",
        "        \"\"\"\r\n",
        "        Usual torch forward function\r\n",
        "        \r\n",
        "        Arguments:\r\n",
        "            tokens {torch tensor} -- Sentence tokens\r\n",
        "        \r\n",
        "        Returns:\r\n",
        "            torch tensor -- Class logits\r\n",
        "        \"\"\"\r\n",
        "        hidden_states = self.transformer(\r\n",
        "            tokens, attention_mask=(tokens > 0).long()\r\n",
        "        )[1]\r\n",
        "\r\n",
        "        # hidden_states = hidden_states[-1][:, 0] # Use the representation of the first token of the last layer\r\n",
        "\r\n",
        "        ft = self.pooler(hidden_states)\r\n",
        "\r\n",
        "        return self.logit(ft)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T9c_puh6NOW",
        "outputId": "292b79eb-38f5-475d-e753-68bca44bf789"
      },
      "source": [
        "import numpy as np\r\n",
        "model = AutoModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\r\n",
        "model=Transformer(model)\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\r\n",
        "x_train = regular_encode(list(df.comment_text.values), tokenizer, maxlen=128)\r\n",
        "y_train = df.toxic.values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWcOyDIqInY5"
      },
      "source": [
        "class bce(nn.Module):\r\n",
        "    def __init__(self, weight=None, size_average=True):\r\n",
        "        super(bce, self).__init__()\r\n",
        "\r\n",
        "    def forward(self, inputs, targets, smooth=1):\r\n",
        "        \r\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\r\n",
        "        \r\n",
        "        #flatten label and prediction tensors\r\n",
        "        inputs = inputs.view(-1)\r\n",
        "        targets = targets.view(-1)\r\n",
        "        \r\n",
        "        one=(targets-1)*torch.log(1-inputs)\r\n",
        "        zero=(targets*torch.log(inputs))\r\n",
        "        loss = torch.mean(one+zero)\r\n",
        "        \r\n",
        "        return loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFTdSJmu7_1m"
      },
      "source": [
        "class JigsawDataset(Dataset):\r\n",
        "    \"\"\"\r\n",
        "    Torch dataset for training and validating\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, x,y):\r\n",
        "        super().__init__()\r\n",
        "        self.y = y \r\n",
        "        self.sentences = x\r\n",
        "        \r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self.sentences.shape[0]\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return torch.tensor(self.sentences[idx]), torch.tensor(self.y[idx])\r\n",
        "\r\n",
        "def fit(model, train_dataset, epochs=1, batch_size=8, lr=5e-4):\r\n",
        "    \r\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\r\n",
        "\r\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "    for epoch in range(epochs):\r\n",
        "        model.train()\r\n",
        "        avg_loss =0\r\n",
        "        optimizer.zero_grad()\r\n",
        "        lss=bce()\r\n",
        "        for step, (x, y_batch) in tqdm(enumerate(train_loader), total=len(train_loader)): \r\n",
        "            \r\n",
        "            y_pred = model(x)\r\n",
        "            \r\n",
        "            loss = lss(y_pred.view(-1).float(), y_batch.float())\r\n",
        "            loss.backward()\r\n",
        "            avg_loss += loss.item() / len(train_loader)\r\n",
        "\r\n",
        "            optimizer.step()\r\n",
        "            #optimizer.step()\r\n",
        "            \r\n",
        "            model.zero_grad()\r\n",
        "            optimizer.zero_grad()\r\n",
        "        print(avg_loss)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "118b62d649fa469c82d291eb8fb2573f",
            "8863fc4089f3460087bd04de7e1b1098",
            "ac1ebd16cd7b44de8a9c9f5beb94077c",
            "84ff9550dbd54a1caf68d95245809fdf",
            "f74017fbaec14ba1bbe24e3507c9ee6f",
            "38f90f58c65e4d54bf00d7a5fada5d4e",
            "691db5f75348412d8802645e2a627d9f",
            "e966d6b016a0441d9eb8125176fae43e"
          ]
        },
        "id": "f8NC82vcMDwx",
        "outputId": "c764ec99-4cb1-4399-f2b7-19d1b8162bcb"
      },
      "source": [
        "train_dataset = JigsawDataset(x_train,y_train)\r\n",
        "fit(model, train_dataset, epochs=10, batch_size=32, lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "118b62d649fa469c82d291eb8fb2573f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=342.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFsQiSNqOyud"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}